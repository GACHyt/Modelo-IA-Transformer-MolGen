{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a0cd539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass\n",
    "#MolGen/Scripts/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "289aa7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%pip install torch\\n%pip install rdkit\\n%pip install pandas\\n%pip install numpy'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"%pip install torch\n",
    "%pip install rdkit\n",
    "%pip install pandas\n",
    "%pip install numpy\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bfbd9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se cargaron 249456 moléculas.\n",
      "Primeras 5 moléculas: ['CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1', 'C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1', 'N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)cc2)cc1', 'CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c2CCCCC3)C1', 'N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#N)C12CCCCC2']\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/aspuru-guzik-group/selfies/refs/heads/master/examples/vae_example/datasets/dataJ_250k_rndm_zinc_drugs_clean.txt\"\n",
    "\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    data = response.read().decode('utf-8')\n",
    "    Corpus = data.strip().split('\\n')\n",
    "\n",
    "print(f\"Se cargaron {len(Corpus)} moléculas.\")\n",
    "print(\"Primeras 5 moléculas:\", Corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5f194b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['C', 'C', '(', '=', 'O', ')', 'O'],\n",
       " ['C', '1', '=', 'C', 'C', '=', 'C', 'C', '=', 'C', '1'],\n",
       " ['C', '(', 'C', '(', '=', 'O', ')', 'O', ')', 'N']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset = [\"CC(=O)O\", \"C1=CC=CC=C1\", \"C(C(=O)O)N\"]\n",
    "Tokens1 = []\n",
    "for i in Dataset:\n",
    "    Tokens1.append(list(i))\n",
    "Tokens1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00217e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(', ')', '1', '=', 'C', 'N', 'O'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Moleculas = [\"CC(=O)O\", \"C1=CC=CC=C1\", \"C(C(=O)O)N\"]\n",
    "Tokens = []\n",
    "#for i in Moleculas:\n",
    "for i in Moleculas:\n",
    "    for x in i:\n",
    "        Tokens.append(x)\n",
    "Tokens = set(Tokens)\n",
    "Tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33546e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<bos>': 1,\n",
       " '<eos>': 9,\n",
       " '=': 2,\n",
       " ')': 3,\n",
       " 'C': 4,\n",
       " 'N': 5,\n",
       " '(': 6,\n",
       " '1': 7,\n",
       " 'O': 8}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear vocabulario como diccionario, dandole como indice de 2 para arriba\n",
    "Vocabulario = {\"<pad>\": 0, \"<bos>\": 1,} #padding e inicio de secunecia\n",
    "Vocabulario[\"<eos>\"] = len(Tokens) + 2 # Final de Secuencia. (Preguntar a Chona)\n",
    "indice = 2\n",
    "for i in Tokens:\n",
    "    Vocabulario[i] = indice\n",
    "    indice += 1\n",
    "Vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deba8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98210e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolDataset(Dataset):\n",
    "    def __init__(self, mols, vocab, max_len = 20): # Guarda los datos para utilizarlos en futuras funciones\n",
    "        self.moleculas = mols\n",
    "        self.vocabulario = vocab\n",
    "        self.max_len = max_len # El len es para completar con el padding si faltan caracteres\n",
    "    \n",
    "    def __len__(self): # Para saber la cantidad de moleculas\n",
    "        return len(self.moleculas)\n",
    "    \n",
    "    def __getitem__(self, nro):\n",
    "        molecula = self.moleculas[nro]\n",
    "        tokens_molecula = [\"<bos>\"] + list(molecula) + [\"<eos>\"] # Tokeniza a molecula seleccionada agregando la token de inicio y de final\n",
    "\n",
    "        tokenizado_vocabulario = [self.vocabulario[t] for t in tokens_molecula] #Convertimos a los numeros del vocabulario (1.....9)\n",
    "\n",
    "        padding = [self.vocabulario[\"<pad>\"]] * (self.max_len - len(tokenizado_vocabulario)) # Definimos la cantidad de ceros que van a ver, la diferencia entre el maximo y las que hay.\n",
    "        tokenizado_vocabulario += padding # Agregamos el padding (1.....9000)\n",
    "        return torch.tensor(tokenizado_vocabulario, dtype = torch.long), molecula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90fd837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MolDataset(Moleculas, Vocabulario) #Se corre la clase para mis moleculas y vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "354a1be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(data, batch_size = 1, shuffle = True) # Usamos dataloader para dar en tandas de a 2 (batch) y para que mezcle las moleculas tokenizadas (shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "881c69c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[1, 4, 7, 5, 4, 4, 5, 4, 4, 5, 4, 7, 9, 0, 0, 0, 0, 0, 0, 0]]), ('C1=CC=CC=C1',)]\n",
      "[tensor([[1, 4, 4, 8, 5, 2, 3, 2, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), ('CC(=O)O',)]\n",
      "[tensor([[1, 4, 8, 4, 8, 5, 2, 3, 2, 3, 6, 9, 0, 0, 0, 0, 0, 0, 0, 0]]), ('C(C(=O)O)N',)]\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d5f38ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrearTensor(Mols, Vocab):\n",
    "    data = MolDataset(Mols, Vocab) #Se corre la clase para mis moleculas y vocabulario\n",
    "    dataloader = DataLoader(data, batch_size = 1, shuffle = True) # Usamos dataloader para dar en tandas de a 2 (batch) y para que mezcle las moleculas tokenizadas (shuffle)\n",
    "    for batch in dataloader:\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2025d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[1, 4, 8, 4, 8, 5, 2, 3, 2, 3, 6, 9, 0, 0, 0, 0, 0, 0, 0, 0]]), ('C(C(=O)O)N',)]\n",
      "[tensor([[1, 4, 7, 5, 4, 4, 5, 4, 4, 5, 4, 7, 9, 0, 0, 0, 0, 0, 0, 0]]), ('C1=CC=CC=C1',)]\n",
      "[tensor([[1, 4, 4, 8, 5, 2, 3, 2, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), ('CC(=O)O',)]\n"
     ]
    }
   ],
   "source": [
    "CrearTensor(Moleculas, Vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7656dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MolGen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
